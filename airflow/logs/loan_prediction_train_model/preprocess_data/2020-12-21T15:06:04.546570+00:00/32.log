[2020-12-21 16:07:38,270] {taskinstance.py:655} INFO - Dependencies all met for <TaskInstance: loan_prediction_train_model.preprocess_data 2020-12-21T15:06:04.546570+00:00 [queued]>
[2020-12-21 16:07:38,309] {taskinstance.py:655} INFO - Dependencies all met for <TaskInstance: loan_prediction_train_model.preprocess_data 2020-12-21T15:06:04.546570+00:00 [queued]>
[2020-12-21 16:07:38,309] {taskinstance.py:866} INFO - 
--------------------------------------------------------------------------------
[2020-12-21 16:07:38,309] {taskinstance.py:867} INFO - Starting attempt 32 of 36
[2020-12-21 16:07:38,309] {taskinstance.py:868} INFO - 
--------------------------------------------------------------------------------
[2020-12-21 16:07:38,329] {taskinstance.py:887} INFO - Executing <Task(LivyBatchOperator): preprocess_data> on 2020-12-21T15:06:04.546570+00:00
[2020-12-21 16:07:38,334] {standard_task_runner.py:53} INFO - Started process 27118 to run task
[2020-12-21 16:07:38,447] {logging_mixin.py:112} INFO - Running %s on host %s <TaskInstance: loan_prediction_train_model.preprocess_data 2020-12-21T15:06:04.546570+00:00 [running]> dcb43f18a24b
[2020-12-21 16:07:38,508] {logging_mixin.py:112} INFO - [2020-12-21 16:07:38,508] {batch.py:214} INFO - Submitting the batch to Livy... Payload:
{
  "file": "/usr/local/airflow/dist/main.py",
  "args": [
    "-job=preprocess_data",
    "-phase=train",
    "-mode=aws",
    "-awsKey=AKIAUW4FKHTMR2UR3INH",
    "-awsSecretKey=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",
    "-s3Bucket=alanchn31-loan-default-prediction"
  ],
  "pyFiles": [
    "/usr/local/airflow/dist/src.zip"
  ],
  "name": "preprocess_data_scheduled__2020-12-21T15:06:04.546570+00:00"
}
[2020-12-21 16:07:38,532] {logging_mixin.py:112} INFO - [2020-12-21 16:07:38,531] {base_hook.py:84} INFO - Using connection to: id: livy. Host: http://ec2-3-238-254-96.compute-1.amazonaws.com, Port: 8998, Schema: None, Login: None, Password: None, extra: None
[2020-12-21 16:07:38,542] {logging_mixin.py:112} INFO - [2020-12-21 16:07:38,542] {http_hook.py:136} INFO - Sending 'POST' to url: http://ec2-3-238-254-96.compute-1.amazonaws.com:8998/batches
[2020-12-21 16:07:38,597] {logging_mixin.py:112} INFO - [2020-12-21 16:07:38,597] {batch.py:166} INFO - Batch successfully submitted with id = 22.
[2020-12-21 16:07:38,600] {logging_mixin.py:112} INFO - [2020-12-21 16:07:38,600] {batch.py:80} INFO - Getting batch 22 status...
[2020-12-21 16:07:38,617] {logging_mixin.py:112} INFO - [2020-12-21 16:07:38,617] {base_hook.py:84} INFO - Using connection to: id: livy. Host: http://ec2-3-238-254-96.compute-1.amazonaws.com, Port: 8998, Schema: None, Login: None, Password: None, extra: None
[2020-12-21 16:07:38,620] {logging_mixin.py:112} INFO - [2020-12-21 16:07:38,620] {http_hook.py:136} INFO - Sending 'GET' to url: http://ec2-3-238-254-96.compute-1.amazonaws.com:8998/batches/22
[2020-12-21 16:07:38,651] {logging_mixin.py:112} INFO - [2020-12-21 16:07:38,650] {batch.py:90} INFO - Batch 22 has not finished yet (state is 'starting')
[2020-12-21 16:07:58,672] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,671] {batch.py:80} INFO - Getting batch 22 status...
[2020-12-21 16:07:58,680] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,679] {base_hook.py:84} INFO - Using connection to: id: livy. Host: http://ec2-3-238-254-96.compute-1.amazonaws.com, Port: 8998, Schema: None, Login: None, Password: None, extra: None
[2020-12-21 16:07:58,682] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,682] {http_hook.py:136} INFO - Sending 'GET' to url: http://ec2-3-238-254-96.compute-1.amazonaws.com:8998/batches/22
[2020-12-21 16:07:58,693] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,693] {batch.py:299} INFO - --------------------------------------------------Full log for batch 22--------------------------------------------------
[2020-12-21 16:07:58,700] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,700] {base_hook.py:84} INFO - Using connection to: id: livy. Host: http://ec2-3-238-254-96.compute-1.amazonaws.com, Port: 8998, Schema: None, Login: None, Password: None, extra: None
[2020-12-21 16:07:58,703] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,703] {http_hook.py:136} INFO - Sending 'GET' to url: http://ec2-3-238-254-96.compute-1.amazonaws.com:8998/batches/22/log?from=0&size=100
[2020-12-21 16:07:58,711] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,710] {batch.py:309} INFO - stdout: 
[2020-12-21 16:07:58,711] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,711] {batch.py:309} INFO - 2020-12-21 16:07:42,034 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2020-12-21 16:07:58,711] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,711] {batch.py:309} INFO - Exception in thread "main" java.io.FileNotFoundException: File hdfs://master:9000/usr/local/airflow/dist/main.py does not exist.
[2020-12-21 16:07:58,711] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,711] {batch.py:309} INFO - 	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:1058)
[2020-12-21 16:07:58,711] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,711] {batch.py:309} INFO - 	at org.apache.hadoop.hdfs.DistributedFileSystem.access$1000(DistributedFileSystem.java:131)
[2020-12-21 16:07:58,711] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,711] {batch.py:309} INFO - 	at org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1118)
[2020-12-21 16:07:58,712] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,711] {batch.py:309} INFO - 	at org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1115)
[2020-12-21 16:07:58,712] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,712] {batch.py:309} INFO - 	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
[2020-12-21 16:07:58,712] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,712] {batch.py:309} INFO - 	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:1125)
[2020-12-21 16:07:58,712] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,712] {batch.py:309} INFO - 	at org.apache.spark.util.Utils$.fetchHcfsFile(Utils.scala:755)
[2020-12-21 16:07:58,712] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,712] {batch.py:309} INFO - 	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:723)
[2020-12-21 16:07:58,712] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,712] {batch.py:309} INFO - 	at org.apache.spark.deploy.DependencyUtils$.downloadFile(DependencyUtils.scala:137)
[2020-12-21 16:07:58,712] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,712] {batch.py:309} INFO - 	at org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7.apply(SparkSubmit.scala:356)
[2020-12-21 16:07:58,713] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,713] {batch.py:309} INFO - 	at org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7.apply(SparkSubmit.scala:356)
[2020-12-21 16:07:58,713] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,713] {batch.py:309} INFO - 	at scala.Option.map(Option.scala:146)
[2020-12-21 16:07:58,713] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,713] {batch.py:309} INFO - 	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:355)
[2020-12-21 16:07:58,713] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,713] {batch.py:309} INFO - 	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:774)
[2020-12-21 16:07:58,713] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,713] {batch.py:309} INFO - 	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
[2020-12-21 16:07:58,713] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,713] {batch.py:309} INFO - 	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
[2020-12-21 16:07:58,713] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,713] {batch.py:309} INFO - 	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
[2020-12-21 16:07:58,714] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,714] {batch.py:309} INFO - 	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
[2020-12-21 16:07:58,714] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,714] {batch.py:309} INFO - 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
[2020-12-21 16:07:58,714] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,714] {batch.py:309} INFO - 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
[2020-12-21 16:07:58,714] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,714] {batch.py:309} INFO - 
stderr: 
[2020-12-21 16:07:58,714] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,714] {batch.py:309} INFO - 
YARN Diagnostics: 
[2020-12-21 16:07:58,715] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,714] {batch.py:309} INFO - spark-submit start failed
[2020-12-21 16:07:58,715] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,715] {batch.py:318} INFO - --------------------------------------------------End of full log for batch 22--------------------------------------------------
[2020-12-21 16:07:58,715] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,715] {batch.py:335} INFO - Closing batch with id = 22
[2020-12-21 16:07:58,722] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,722] {base_hook.py:84} INFO - Using connection to: id: livy. Host: http://ec2-3-238-254-96.compute-1.amazonaws.com, Port: 8998, Schema: None, Login: None, Password: None, extra: None
[2020-12-21 16:07:58,723] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,723] {http_hook.py:136} INFO - Sending 'DELETE' to url: http://ec2-3-238-254-96.compute-1.amazonaws.com:8998/batches/22
[2020-12-21 16:07:58,733] {logging_mixin.py:112} INFO - [2020-12-21 16:07:58,733] {batch.py:340} INFO - Batch 22 has been closed
[2020-12-21 16:07:58,742] {taskinstance.py:1128} ERROR - Batch 22 failed with state 'dead'
Traceback (most recent call last):
  File "/opt/bitnami/python/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 966, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/usr/local/airflow/plugins/airflow_livy/batch.py", line 173, in execute
    ).execute(context)
  File "/opt/bitnami/python/lib/python3.6/site-packages/airflow/sensors/base_sensor_operator.py", line 107, in execute
    while not self.poke(context):
  File "/usr/local/airflow/plugins/airflow_livy/batch.py", line 96, in poke
    raise AirflowException(f"Batch {self.batch_id} failed with state '{state}'")
airflow.exceptions.AirflowException: Batch 22 failed with state 'dead'
[2020-12-21 16:07:58,744] {taskinstance.py:1151} INFO - Marking task as UP_FOR_RETRY
[2020-12-21 16:08:03,303] {logging_mixin.py:112} INFO - [2020-12-21 16:08:03,303] {local_task_job.py:103} INFO - Task exited with return code 1
